{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f003f012-c68e-4515-819d-18fc593aea45",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, log_loss, confusion_matrix\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "# ==========================================\n",
    "# 1. åŸºç¡€é…ç½®ï¼šå®šä¹‰åˆ—ç´¢å¼•ï¼ˆåŸºäºExcelç»“æ„ï¼‰\n",
    "# ==========================================\n",
    "cat_indices = [1,3,4,5,6,7,8,9]        # åˆ†ç±»å˜é‡ç´¢å¼•\n",
    "cont_indices = [2]                     # è¿ç»­å˜é‡ç´¢å¼• \n",
    "item_indices = list(range(10, 80))     # é—®å·é¢˜ç›®ç´¢å¼• \n",
    "\n",
    "# ç›®æ ‡å˜é‡ç´¢å¼• (åŸå§‹è¿ç»­åˆ†ï¼Œåç»­å°†è½¬ä¸ºåˆ†ç±»æ ‡ç­¾)\n",
    "target_index = 91 \n",
    "\n",
    "# å¸¸ç”¨é›†åˆ\n",
    "demographics = cat_indices + cont_indices # æ‰€æœ‰äººå£å­¦\n",
    "all_items = item_indices                  # æ‰€æœ‰é—®å·é¢˜\n",
    "\n",
    "# ==========================================\n",
    "# 2. æ¨¡å‹ç‰¹å¾é…ç½®\n",
    "# ==========================================\n",
    "model_feature_config = {\n",
    "    'LASSO_LR': [2,71,80,72,73,76,78,79,24,29,30,35,37,\n",
    "                12,43,14,16,18,62,47,65,67,68],           \n",
    "    'SVM': [16,43,37,68,2,76,75,80,24,7,62,21,72,78,57,\n",
    "                20,67,18],                                \n",
    "    'XGBoost': [62,80,76,68,67,16,73,65,60,72,75,78,43,\n",
    "               77,47,71,79,70,37,23,21,64,22,50,12,74,\n",
    "               61,18,63,14,19,28],                        \n",
    "    'LightGBM': [76,80,62,16,43,2,72,68],                 \n",
    "    'Random Forest': [80,76,68,79,78,77,16,67,72,43,60,\n",
    "                     62,75,70,71,73,50,47,64,12,2,65]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c414b58e-9290-4052-a6e4-8ff4305c4045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. æ•°æ®è¯»å–ä¸æ™ºèƒ½æ¸…æ´—\n",
    "# ==========================================\n",
    "file_path = \"å†…éƒ¨éªŒè¯æ•°æ®é›†.xlsx\"\n",
    "df = pd.read_excel(file_path, header=2)\n",
    "\n",
    "if target_index < len(df.columns):\n",
    "    df = df.dropna(subset=[df.columns[target_index]])\n",
    "else:\n",
    "    raise ValueError(f\"ç›®æ ‡åˆ—ç´¢å¼• {target_index} è¶…å‡ºäº†æ•°æ®åˆ—æ•°èŒƒå›´ (æ€»åˆ—æ•°: {len(df.columns)})\")\n",
    "\n",
    "cat_names = [df.columns[i] for i in cat_indices if i < len(df.columns)]\n",
    "cont_names = [df.columns[i] for i in cont_indices if i < len(df.columns)]\n",
    "item_names = [df.columns[i] for i in item_indices if i < len(df.columns)]\n",
    "all_cont_names = cont_names + item_names # æ‰€æœ‰éœ€è¦è½¬ä¸ºæ•°å­—çš„åˆ—\n",
    "\n",
    "for col in all_cont_names:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ac74ce-87d2-4ce9-9323-eb6a2b237dde",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. å‡†å¤‡å»ºæ¨¡æ•°æ®\n",
    "# ==========================================\n",
    "all_needed_indices = set()\n",
    "for indices in model_feature_config.values():\n",
    "    all_needed_indices.update(indices)\n",
    "all_needed_indices.add(target_index)\n",
    "\n",
    "# å°†ç´¢å¼•è½¬ä¸ºåˆ—å\n",
    "all_needed_cols = [df.columns[i] for i in all_needed_indices if i < len(df.columns)]\n",
    "\n",
    "# å‰”é™¤ç¼ºå¤±å€¼ (ä»…æ£€æŸ¥éœ€è¦çš„åˆ—)\n",
    "df_clean = df.dropna(subset=[df.columns[target_index]]).copy()\n",
    "print(f\"åŸå§‹æ ·æœ¬é‡: {len(df)}\")\n",
    "print(f\"æ¸…æ´—åæœ‰æ•ˆæ ·æœ¬é‡ (ä»…å‰”é™¤æ— æ ‡ç­¾æ ·æœ¬): {len(df_clean)}\")\n",
    "\n",
    "# 4.1 å¦‚æœæ ·æœ¬é‡ä¸º0ï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯\n",
    "if len(df_clean) == 0:\n",
    "    print(\"\\nã€ä¸¥é‡é”™è¯¯ã€‘æœ‰æ•ˆæ ·æœ¬é‡ä¸º0ï¼è¯·æ£€æŸ¥ä»¥ä¸‹ç¼ºå¤±å€¼æƒ…å†µï¼š\")\n",
    "    print(\"(æ˜¾ç¤ºç¼ºå¤±å€¼æœ€å¤šçš„å‰10ä¸ªåˆ—)\")\n",
    "    na_counts = df[all_needed_cols].isna().sum().sort_values(ascending=False)\n",
    "    print(na_counts.head(10))\n",
    "    raise ValueError(\"æ•°æ®æ¸…æ´—åæ²¡æœ‰å‰©ä½™æ ·æœ¬ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°åˆ—çš„æ•°æ®è´¨é‡æˆ–ç´¢å¼•é…ç½®ã€‚\")\n",
    "\n",
    "# 1. åˆ’åˆ†ç´¢å¼• (Train/Test)\n",
    "train_idx, test_idx = train_test_split(df_clean.index, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. æå–åŸå§‹å¾—åˆ†ç”¨äºè®¡ç®—åˆ†ç±»é˜ˆå€¼\n",
    "y_score_train = df_clean.loc[train_idx, df.columns[target_index]].astype(float)\n",
    "y_score_test = df_clean.loc[test_idx, df.columns[target_index]].astype(float)\n",
    "\n",
    "# 3. åœ¨è®­ç»ƒé›†ä¸Šè®¡ç®—é˜ˆå€¼\n",
    "q1 = y_score_train.quantile(1/3)\n",
    "q2 = y_score_train.quantile(2/3)\n",
    "bins = [-np.inf, q1, q2, np.inf]\n",
    "\n",
    "print(f\"Label cut thresholds (calculated on Train only): Q1={q1:.2f}, Q2={q2:.2f}\")\n",
    "\n",
    "# 4. åº”ç”¨é˜ˆå€¼ç”Ÿæˆæ ‡ç­¾ (0:Low, 1:Medium, 2:High)\n",
    "y_train = pd.cut(y_score_train, bins=bins, labels=[0, 1, 2], include_lowest=True).astype(int)\n",
    "y_test = pd.cut(y_score_test, bins=bins, labels=[0, 1, 2], include_lowest=True).astype(int)\n",
    "\n",
    "print(\"Train class counts:\", y_train.value_counts().sort_index().values)\n",
    "print(\"Test class counts: \", y_test.value_counts().sort_index().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d417e3-d2f6-4093-be29-392dacc0f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4703fa-6eda-4668-a4cf-02c9128b57f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. ç½‘æ ¼æœç´¢ä¸æ¨¡å‹è®­ç»ƒ\n",
    "# ==========================================\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, accuracy_score\n",
    "# ==========================================\n",
    "\n",
    "models = {\n",
    "    'LASSO_LR': LogisticRegression(solver='saga', penalty='elasticnet', max_iter=10000, random_state=42),\n",
    "    \n",
    "    'SVM': SVC(probability=True, random_state=42),\n",
    "    \n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    \n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    \n",
    "    'LightGBM': lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "}\n",
    "# 5.1 å®šä¹‰è¶…å‚æ•°ç½‘æ ¼\n",
    "param_grids = {\n",
    "    'LASSO_LR': {\n",
    "        'classifier__l1_ratio': [0.1, 0.5, 0.9], \n",
    "        'classifier__C': [0.01, 0.1, 1, 4, 10] \n",
    "    },\n",
    "    \n",
    "    'Random Forest': {\n",
    "        'classifier__n_estimators': [100, 500, 1000], \n",
    "        'classifier__max_features': ['sqrt', None], \n",
    "        'classifier__max_depth': [None, 10, 20],   \n",
    "        'classifier__min_samples_split': [2, 5]\n",
    "    },\n",
    "    \n",
    "    'XGBoost': {\n",
    "        'classifier__max_depth': [3, 6, 11], \n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.3], \n",
    "        'classifier__n_estimators': [200,300,500, 1000],\n",
    "        'classifier__reg_alpha': [0, 0.1, 1],     \n",
    "        'classifier__reg_lambda': [1, 5]          \n",
    "    },\n",
    "    \n",
    "    'SVM': {\n",
    "        'classifier__C': [0.1, 1, 4, 10], \n",
    "        'classifier__gamma': ['scale', 0.135],   \n",
    "        'classifier__kernel': ['rbf']            \n",
    "    },\n",
    "    \n",
    "    'LightGBM': {\n",
    "        'classifier__learning_rate': [0.01, 0.05],\n",
    "        'classifier__n_estimators': [500, 1000],\n",
    "        'classifier__num_leaves': [31, 50],\n",
    "        'classifier__reg_alpha': [0.1, 1]\n",
    "    }\n",
    "}\n",
    "\n",
    "# 5.2 å®šä¹‰ä¼˜åŒ–ç›®æ ‡ï¼šMacro-AUC (One-vs-Rest)\n",
    "scoring_metric = 'roc_auc_ovr'\n",
    "\n",
    "# å­˜å‚¨æœ€ä½³æ¨¡å‹\n",
    "best_models = {} \n",
    "\n",
    "print(f\"\\nå¼€å§‹ 5æŠ˜äº¤å‰éªŒè¯ Grid Search (ä¼˜åŒ–ç›®æ ‡: {scoring_metric})...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name, model_base in models.items():\n",
    "    print(f\"æ­£åœ¨ä¼˜åŒ–æ¨¡å‹: {name} ...\")\n",
    "    \n",
    "    # --- A. å‡†å¤‡æ•°æ®ç‰¹å¾ ---\n",
    "    feature_indices = model_feature_config[name]\n",
    "    valid_indices = [i for i in feature_indices if i < len(df.columns)]\n",
    "    feature_names = [df.columns[i] for i in valid_indices]\n",
    "    \n",
    "    current_cat = [f for f in feature_names if f in cat_names]\n",
    "    current_cont = [f for f in feature_names if f not in cat_names]\n",
    "    \n",
    "    X_train_curr = df_clean.loc[train_idx, feature_names]\n",
    "    \n",
    "    # --- B. æ„å»º Pipeline ---\n",
    "    transformers = []\n",
    "    if current_cont:\n",
    "        transformers.append(('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')), \n",
    "            ('scaler', StandardScaler())\n",
    "        ]), current_cont))\n",
    "    if current_cat:\n",
    "        transformers.append(('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')), \n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ]), current_cat))\n",
    "        \n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', ColumnTransformer(transformers=transformers)),\n",
    "        ('classifier', model_base)\n",
    "    ])\n",
    "    \n",
    "    # --- C. æ‰§è¡Œç½‘æ ¼æœç´¢ ---\n",
    "    current_grid = param_grids.get(name, {})\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=current_grid,\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        scoring=scoring_metric, \n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # è®­ç»ƒ\n",
    "    grid.fit(X_train_curr, y_train)\n",
    "    \n",
    "    # --- D. ä¿å­˜ä¸è®°å½• ---\n",
    "    best_models[name] = grid.best_estimator_\n",
    "    \n",
    "    print(f\"  > æœ€ä½³ AUC (CVå¹³å‡): {grid.best_score_:.4f}\")\n",
    "    print(f\"  > æœ€ä½³å‚æ•°: {grid.best_params_}\")\n",
    "    \n",
    "    # ç®€å•æµ‹è¯•\n",
    "    X_test_curr = df_clean.loc[test_idx, feature_names]\n",
    "    y_test_pred = grid.best_estimator_.predict(X_test_curr)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"  > ç‹¬ç«‹æµ‹è¯•é›† Accuracy: {test_acc:.4f}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nç½‘æ ¼æœç´¢å®Œæˆï¼æœ€ä½³æ¨¡å‹å·²ä¿å­˜è‡³ best_models å­—å…¸ä¸­ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c9b194-3aca-467b-91ae-415ada794684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 7. å†…éƒ¨éªŒè¯ï¼šå« 95% CI å¹¶æŒ‰ AUC æ’åº\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, cohen_kappa_score, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# --- é…ç½® ---\n",
    "N_BOOTSTRAPS = 1000 \n",
    "RNG_SEED = 42\n",
    "\n",
    "# --- è¾…åŠ©å‡½æ•° ---\n",
    "def format_ci(score, lower, upper):\n",
    "    return f\"{score:.3f} ({lower:.3f}-{upper:.3f})\"\n",
    "\n",
    "def compute_metrics_once(y_true, y_pred, y_prob, n_classes):\n",
    "    # 1. åŸºç¡€æŒ‡æ ‡\n",
    "    if n_classes > 2:\n",
    "        auc = roc_auc_score(y_true, y_prob, multi_class='ovr', average='macro')\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    else:\n",
    "        y_prob_pos = y_prob[:, 1]\n",
    "        auc = roc_auc_score(y_true, y_prob_pos)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    \n",
    "    # 2. Brier Score\n",
    "    y_true_onehot = label_binarize(y_true, classes=range(n_classes))\n",
    "    if n_classes == 2 and y_true_onehot.shape[1] == 1:\n",
    "        y_true_onehot = np.hstack([1 - y_true_onehot, y_true_onehot])\n",
    "    brier = np.mean(np.sum((y_prob - y_true_onehot) ** 2, axis=1))\n",
    "    \n",
    "    # 3. Sens/Spec/PPV/NPV\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(n_classes))\n",
    "    sens_list, spec_list, ppv_list, npv_list = [], [], [], []\n",
    "    for i in range(n_classes):\n",
    "        tp = cm[i, i]\n",
    "        fp = cm[:, i].sum() - tp\n",
    "        fn = cm[i, :].sum() - tp\n",
    "        tn = cm.sum() - tp - fp - fn\n",
    "        \n",
    "        sens_list.append(tp / (tp + fn) if (tp + fn) > 0 else 0)\n",
    "        spec_list.append(tn / (tn + fp) if (tn + fp) > 0 else 0)\n",
    "        ppv_list.append(tp / (tp + fp) if (tp + fp) > 0 else 0)\n",
    "        npv_list.append(tn / (tn + fn) if (tn + fn) > 0 else 0)\n",
    "        \n",
    "    return {\n",
    "        'AUC': auc, 'Brier Score': brier, 'Accuracy': acc, 'F1-Score': f1, 'Kappa': kappa,\n",
    "        'Sensitivity': np.mean(sens_list), 'Specificity': np.mean(spec_list),\n",
    "        'PPV': np.mean(ppv_list), 'NPV': np.mean(npv_list)\n",
    "    }\n",
    "\n",
    "# --- ä¸»è®¡ç®—å¾ªç¯ ---\n",
    "final_results = []\n",
    "y_test_arr = np.array(y_test)\n",
    "n_classes = len(np.unique(y_test_arr))\n",
    "\n",
    "print(f\"å¼€å§‹è®¡ç®— Bootstrap 95% CI (é‡é‡‡æ · {N_BOOTSTRAPS} æ¬¡)...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    print(f\"æ­£åœ¨è¯„ä¼°: {name} ...\")\n",
    "    \n",
    "    # å‡†å¤‡æ•°æ®\n",
    "    feature_indices = model_feature_config[name]\n",
    "    valid_indices = [i for i in feature_indices if i < len(df.columns)]\n",
    "    feature_names = [df.columns[i] for i in valid_indices]\n",
    "    X_test_curr = df_clean.loc[test_idx, feature_names]\n",
    "    \n",
    "    # é¢„æµ‹\n",
    "    y_pred_full = model.predict(X_test_curr)\n",
    "    y_prob_full = model.predict_proba(X_test_curr)\n",
    "    \n",
    "    # ç‚¹ä¼°è®¡\n",
    "    original_metrics = compute_metrics_once(y_test_arr, y_pred_full, y_prob_full, n_classes)\n",
    "    \n",
    "    # Bootstrap\n",
    "    boot_metrics = {k: [] for k in original_metrics.keys()}\n",
    "    for i in range(N_BOOTSTRAPS):\n",
    "        indices = resample(np.arange(len(y_test_arr)), replace=True, random_state=i)\n",
    "        if len(np.unique(y_test_arr[indices])) < n_classes: continue \n",
    "        \n",
    "        m = compute_metrics_once(y_test_arr[indices], y_pred_full[indices], y_prob_full[indices], n_classes)\n",
    "        for k, v in m.items():\n",
    "            boot_metrics[k].append(v)\n",
    "            \n",
    "    # è®¡ç®— CI\n",
    "    res = {'Model': name}\n",
    "    for k, v in boot_metrics.items():\n",
    "        lower = np.percentile(v, 2.5)\n",
    "        upper = np.percentile(v, 97.5)\n",
    "        res[k] = format_ci(original_metrics[k], lower, upper)\n",
    "    final_results.append(res)\n",
    "\n",
    "# --- ç”Ÿæˆè¡¨æ ¼å¹¶æŒ‰ AUC æ’åº ---\n",
    "df_final_ci = pd.DataFrame(final_results)\n",
    "\n",
    "# æå– AUC æ‹¬å·å‰çš„æ•°å€¼è¿›è¡Œæ’åº\n",
    "df_final_ci['AUC_Value'] = df_final_ci['AUC'].apply(lambda x: float(x.split(' ')[0]))\n",
    "df_final_ci = df_final_ci.sort_values(by='AUC_Value', ascending=False).drop(columns=['AUC_Value'])\n",
    "\n",
    "print(\"\\n=== å†…éƒ¨éªŒè¯æœ€ç»ˆç»“æœ (æŒ‰ AUC é™åº) ===\")\n",
    "display(df_final_ci)\n",
    "\n",
    "# å¯¼å‡º\n",
    "df_final_ci.to_excel(\"Table_Internal_Validation_Sorted.xlsx\", index=False)\n",
    "print(\"è¡¨æ ¼å·²ä¿å­˜è‡³æœ¬åœ°ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2400a0-ed57-472d-9824-e73fceeae333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 7. å†…éƒ¨éªŒè¯ï¼šCalibration & DCA\n",
    "# ==========================================\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "import numpy as np\n",
    "\n",
    "# --- A. ç»˜å›¾è®¾ç½® ---\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams['figure.titlesize'] = 16\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "\n",
    "# ç±»åˆ«å®šä¹‰\n",
    "CLASS_NAMES = {0: \"Low Trust\", 1: \"Medium Trust\", 2: \"High Trust\"}\n",
    "colors = ['#BD3C29', '#0072B2', '#E69F00', '#009E73', '#CC79A7'] \n",
    "\n",
    "# --- B. å®šä¹‰ DCA è®¡ç®—å‡½æ•° ---\n",
    "def calculate_net_benefit(y_true, y_prob, thresholds):\n",
    "    net_benefits = []\n",
    "    n = len(y_true)\n",
    "    for pt in thresholds:\n",
    "        pred_pos = y_prob >= pt\n",
    "        tp = np.sum((y_true == 1) & (pred_pos))\n",
    "        fp = np.sum((y_true == 0) & (pred_pos))\n",
    "        if pt == 1.0:\n",
    "            nb = -np.inf\n",
    "        else:\n",
    "            weight = pt / (1 - pt)\n",
    "            nb = (tp / n) - (fp / n) * weight\n",
    "        net_benefits.append(nb)\n",
    "    return np.array(net_benefits)\n",
    "\n",
    "# --- C. å¾ªç¯ç»˜åˆ¶å†…éƒ¨éªŒè¯å›¾ ---\n",
    "print(\"å¼€å§‹ç»˜åˆ¶ã€å†…éƒ¨éªŒè¯ã€‘(Derivation Cohort) çš„å›¾è¡¨...\")\n",
    "\n",
    "# è·å–æ’åºåçš„æ¨¡å‹å\n",
    "if 'df_final_ci' in locals() and 'Model' in df_final_ci.columns:\n",
    "    sorted_model_names = df_final_ci['Model'].tolist()\n",
    "else:\n",
    "    sorted_model_names = list(best_models.keys())\n",
    "\n",
    "for class_id, class_label in CLASS_NAMES.items():\n",
    "    print(f\"æ­£åœ¨ç»˜åˆ¶: {class_label} ...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6), dpi=300)\n",
    "    \n",
    "    # å­å›¾ 1: Calibration Plot\n",
    "    axes[0].plot([0, 1], [0, 1], \"k:\", label=\"Perfectly Calibrated\", linewidth=1.5)\n",
    "    y_test_binary = (y_test == class_id).astype(int)\n",
    "    \n",
    "    for i, name in enumerate(sorted_model_names):\n",
    "        if name not in best_models: continue\n",
    "        model = best_models[name]\n",
    "        color = colors[i % len(colors)]\n",
    "        \n",
    "        feature_indices = model_feature_config[name]\n",
    "        valid_indices = [idx for idx in feature_indices if idx < len(df.columns)]\n",
    "        feature_names = [df.columns[idx] for idx in valid_indices]\n",
    "        X_curr = df_clean.loc[test_idx, feature_names]\n",
    "        \n",
    "        y_prob = model.predict_proba(X_curr)[:, class_id]\n",
    "        frac_pos, mean_pred = calibration_curve(y_test_binary, y_prob, n_bins=10)\n",
    "        \n",
    "        axes[0].plot(mean_pred, frac_pos, \"s-\", label=name, color=color, linewidth=2, markersize=5, alpha=0.9)\n",
    "    \n",
    "    axes[0].set_title(f\"Calibration Plot: {class_label}\\n(Derivation Cohort)\", fontweight='bold')\n",
    "    axes[0].set_xlabel(\"Predicted Probability\", fontweight='bold')\n",
    "    axes[0].set_ylabel(\"Observed Probability\", fontweight='bold')\n",
    "    axes[0].legend(loc=\"upper left\")\n",
    "    axes[0].text(0.6, 0.1, f\"N = {len(y_test)}\", transform=axes[0].transAxes, \n",
    "                 fontsize=12, bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "    # å­å›¾ 2: DCA Plot\n",
    "    dca_thresholds = np.linspace(0.01, 0.99, 100)\n",
    "    all_pos_rate = np.mean(y_test_binary)\n",
    "    nb_all = all_pos_rate - (1 - all_pos_rate) * (dca_thresholds / (1 - dca_thresholds))\n",
    "    nb_none = np.zeros_like(dca_thresholds)\n",
    "    \n",
    "    axes[1].plot(dca_thresholds, nb_all, \"k:\", label=\"Treat All\", linewidth=1.5, alpha=0.7)\n",
    "    axes[1].plot(dca_thresholds, nb_none, \"k--\", label=\"Treat None\", linewidth=1.5, alpha=0.7)\n",
    "    \n",
    "    for i, name in enumerate(sorted_model_names):\n",
    "        if name not in best_models: continue\n",
    "        model = best_models[name]\n",
    "        color = colors[i % len(colors)]\n",
    "        \n",
    "        feature_indices = model_feature_config[name]\n",
    "        valid_indices = [idx for idx in feature_indices if idx < len(df.columns)]\n",
    "        feature_names = [df.columns[idx] for idx in valid_indices]\n",
    "        X_curr = df_clean.loc[test_idx, feature_names]\n",
    "        \n",
    "        y_prob = model.predict_proba(X_curr)[:, class_id]\n",
    "        nb_model = calculate_net_benefit(y_test_binary, y_prob, dca_thresholds)\n",
    "        axes[1].plot(dca_thresholds, nb_model, \"-\", label=name, color=color, linewidth=2.5, alpha=0.9)\n",
    "    \n",
    "    axes[1].set_title(f\"Decision Curve: {class_label}\\n(Derivation Cohort)\", fontweight='bold')\n",
    "    axes[1].set_xlabel(\"Threshold Probability\", fontweight='bold')\n",
    "    axes[1].set_ylabel(\"Net Benefit\", fontweight='bold')\n",
    "    axes[1].legend(loc=\"upper right\")\n",
    "    axes[1].set_xlim([0, 0.8])\n",
    "    y_max = max(np.max(nb_all[(dca_thresholds < 0.8)]), 0.2) * 1.1 \n",
    "    axes[1].set_ylim([-0.05, y_max])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"Internal_Fig_{class_label.replace(' ', '_')}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(f\"Internal_Fig_{class_label.replace(' ', '_')}.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"å†…éƒ¨éªŒè¯å›¾è¡¨ç»˜åˆ¶å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1871742b-e6d1-4da1-add9-372322f8261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 9. å¤–éƒ¨éªŒè¯ (External Validation)\n",
    "# ==========================================\n",
    "EXTERNAL_FILE_PATH = \"å¤–éƒ¨éªŒè¯æ•°æ®é›†.xlsx\" \n",
    "\n",
    "print(f\"\\næ­£åœ¨åŠ è½½å¤–éƒ¨éªŒè¯æ•°æ®: {EXTERNAL_FILE_PATH} ...\")\n",
    "\n",
    "try:\n",
    "    # 1. åŠ è½½æ•°æ®\n",
    "    df_ext = pd.read_excel(EXTERNAL_FILE_PATH, header=2)\n",
    "    \n",
    "    # 2. é¢„å¤„ç†ç›®æ ‡å˜é‡\n",
    "    if target_index < len(df_ext.columns):\n",
    "        df_ext = df_ext.dropna(subset=[df_ext.columns[target_index]]).copy()\n",
    "        # å¤„ç†è¿ç»­å˜é‡\n",
    "        for col in cont_names: \n",
    "            if col in df_ext.columns:\n",
    "                df_ext[col] = pd.to_numeric(df_ext[col], errors='coerce')\n",
    "        \n",
    "        # ç”Ÿæˆæ ‡ç­¾\n",
    "        y_ext_score = df_ext.iloc[:, target_index].astype(float)\n",
    "        y_ext = pd.cut(y_ext_score, bins=bins, labels=[0, 1, 2], include_lowest=True).astype(int)\n",
    "        \n",
    "        print(f\"å¤–éƒ¨éªŒè¯é›†æœ‰æ•ˆæ ·æœ¬é‡: {len(df_ext)}\")\n",
    "        print(f\"ç±»åˆ«åˆ†å¸ƒ: {y_ext.value_counts().sort_index().to_dict()}\")\n",
    "        \n",
    "        # 3. è¯„ä¼°å¾ªç¯\n",
    "        ext_results_list = []\n",
    "        y_ext_arr = np.array(y_ext)\n",
    "        n_classes_ext = len(np.unique(y_ext_arr))\n",
    "        \n",
    "        print(f\"\\nå¼€å§‹è¯„ä¼°å¤–éƒ¨éªŒè¯é›† (Bootstrap {N_BOOTSTRAPS} æ¬¡)...\")\n",
    "        \n",
    "        for name, model in best_models.items():\n",
    "            print(f\"æ­£åœ¨éªŒè¯: {name} ...\")\n",
    "            \n",
    "            # æå–å¯¹åº”ç‰¹å¾\n",
    "            feature_indices = model_feature_config[name]\n",
    "            valid_indices = [i for i in feature_indices if i < len(df_ext.columns)]\n",
    "            feature_names = [df_ext.columns[i] for i in valid_indices]\n",
    "            X_ext_curr = df_ext[feature_names]\n",
    "            \n",
    "            # é¢„æµ‹ \n",
    "            y_pred_ext = model.predict(X_ext_curr)\n",
    "            y_prob_ext = model.predict_proba(X_ext_curr)\n",
    "            \n",
    "            # è®¡ç®—æŒ‡æ ‡\n",
    "            # ç‚¹ä¼°è®¡\n",
    "            orig_metrics = compute_metrics_once(y_ext_arr, y_pred_ext, y_prob_ext, n_classes_ext)\n",
    "            \n",
    "            # Bootstrap CI\n",
    "            boot_metrics = {k: [] for k in orig_metrics.keys()}\n",
    "            for i in range(N_BOOTSTRAPS):\n",
    "                idx = resample(np.arange(len(y_ext_arr)), replace=True, random_state=i)\n",
    "                if len(np.unique(y_ext_arr[idx])) < n_classes_ext: continue\n",
    "                \n",
    "                m = compute_metrics_once(y_ext_arr[idx], y_pred_ext[idx], y_prob_ext[idx], n_classes_ext)\n",
    "                for k, v in m.items():\n",
    "                    boot_metrics[k].append(v)\n",
    "            \n",
    "            # æ ¼å¼åŒ–ç»“æœ\n",
    "            res = {'Model': name}\n",
    "            for k, v in boot_metrics.items():\n",
    "                lower = np.percentile(v, 2.5)\n",
    "                upper = np.percentile(v, 97.5)\n",
    "                res[k] = format_ci(orig_metrics[k], lower, upper)\n",
    "            ext_results_list.append(res)\n",
    "            \n",
    "        # 4. ç”Ÿæˆå¤–éƒ¨éªŒè¯è¡¨æ ¼\n",
    "        df_ext_results = pd.DataFrame(ext_results_list)\n",
    "        \n",
    "        # åŒæ ·æŒ‰ AUC æ’åº\n",
    "        df_ext_results['AUC_Sort'] = df_ext_results['AUC'].apply(lambda x: float(x.split(' ')[0]))\n",
    "        df_ext_results = df_ext_results.sort_values('AUC_Sort', ascending=False).drop('AUC_Sort', axis=1)\n",
    "        \n",
    "        print(\"\\n=== å¤–éƒ¨éªŒè¯æœ€ç»ˆç»“æœ (External Validation) ===\")\n",
    "        display(df_ext_results)\n",
    "        \n",
    "        # å¯¼å‡º\n",
    "        df_ext_results.to_excel(\"Table_External_Validation_Sorted.xlsx\", index=False)\n",
    "        \n",
    "    else:\n",
    "        print(\"é”™è¯¯ï¼šå¤–éƒ¨æ•°æ®é›†ä¸­æ‰¾ä¸åˆ°ç›®æ ‡åˆ—ï¼Œè¯·æ£€æŸ¥åˆ—ç´¢å¼•æ˜¯å¦ä¸€è‡´ã€‚\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {EXTERNAL_FILE_PATH}ï¼Œè¯·ä¸Šä¼ æˆ–ä¿®æ”¹è·¯å¾„ã€‚\")\n",
    "except Exception as e:\n",
    "    print(f\"å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba214dd0-80af-4142-9f43-1e1231eae85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 10. å¤–éƒ¨éªŒè¯å¯è§†åŒ–ï¼šCalibration & DCA\n",
    "# ==========================================\n",
    "if 'df_ext' not in locals() or 'y_ext' not in locals():\n",
    "    print(\"é”™è¯¯ï¼šè¯·å…ˆè¿è¡Œ Step 9 ç”Ÿæˆå¤–éƒ¨éªŒè¯æ•°æ® df_extï¼\")\n",
    "else:\n",
    "    print(\"å¼€å§‹ç»˜åˆ¶ã€å¤–éƒ¨éªŒè¯ã€‘(External Validation Cohort) çš„å›¾è¡¨...\")\n",
    "    \n",
    "    # è·å–æ’åº\n",
    "    if 'df_ext_results' in locals() and 'Model' in df_ext_results.columns:\n",
    "        sorted_model_names = df_ext_results['Model'].tolist()\n",
    "    else:\n",
    "        sorted_model_names = list(best_models.keys())\n",
    "        \n",
    "    for class_id, class_label in CLASS_NAMES.items():\n",
    "        print(f\"æ­£åœ¨ç»˜åˆ¶: {class_label} ...\")\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 6), dpi=300)\n",
    "        \n",
    "        # å­å›¾ 1: External Calibration\n",
    "        axes[0].plot([0, 1], [0, 1], \"k:\", label=\"Perfectly Calibrated\", linewidth=1.5)\n",
    "        y_ext_arr = np.array(y_ext)\n",
    "        y_ext_binary = (y_ext_arr == class_id).astype(int)\n",
    "        \n",
    "        for i, name in enumerate(sorted_model_names):\n",
    "            if name not in best_models: continue\n",
    "            model = best_models[name]\n",
    "            color = colors[i % len(colors)]\n",
    "            \n",
    "            feature_indices = model_feature_config[name]\n",
    "            valid_indices = [idx for idx in feature_indices if idx < len(df_ext.columns)]\n",
    "            feature_names = [df_ext.columns[idx] for idx in valid_indices]\n",
    "            X_ext_curr = df_ext[feature_names] # æ³¨æ„ï¼šè¿™é‡Œç”¨ df_ext\n",
    "            \n",
    "            y_prob = model.predict_proba(X_ext_curr)[:, class_id]\n",
    "            frac_pos, mean_pred = calibration_curve(y_ext_binary, y_prob, n_bins=10)\n",
    "            \n",
    "            axes[0].plot(mean_pred, frac_pos, \"s-\", label=name, color=color, linewidth=2, markersize=5, alpha=0.9)\n",
    "        \n",
    "        axes[0].set_title(f\"Calibration Plot: {class_label}\\n(External Validation Cohort)\", fontweight='bold')\n",
    "        axes[0].set_xlabel(\"Predicted Probability\", fontweight='bold')\n",
    "        axes[0].set_ylabel(\"Observed Probability\", fontweight='bold')\n",
    "        axes[0].legend(loc=\"upper left\")\n",
    "        \n",
    "        axes[0].text(0.6, 0.1, f\"N = {len(y_ext)}\", transform=axes[0].transAxes, \n",
    "                     fontsize=12, bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "        # å­å›¾ 2: External DCA\n",
    "        dca_thresholds = np.linspace(0.01, 0.99, 100)\n",
    "        all_pos_rate = np.mean(y_ext_binary)\n",
    "        nb_all = all_pos_rate - (1 - all_pos_rate) * (dca_thresholds / (1 - dca_thresholds))\n",
    "        nb_none = np.zeros_like(dca_thresholds)\n",
    "        \n",
    "        axes[1].plot(dca_thresholds, nb_all, \"k:\", label=\"Treat All\", linewidth=1.5, alpha=0.7)\n",
    "        axes[1].plot(dca_thresholds, nb_none, \"k--\", label=\"Treat None\", linewidth=1.5, alpha=0.7)\n",
    "        \n",
    "        for i, name in enumerate(sorted_model_names):\n",
    "            if name not in best_models: continue\n",
    "            model = best_models[name]\n",
    "            color = colors[i % len(colors)]\n",
    "            \n",
    "            feature_indices = model_feature_config[name]\n",
    "            valid_indices = [idx for idx in feature_indices if idx < len(df_ext.columns)]\n",
    "            feature_names = [df_ext.columns[idx] for idx in valid_indices]\n",
    "            X_ext_curr = df_ext[feature_names]\n",
    "            \n",
    "            y_prob = model.predict_proba(X_ext_curr)[:, class_id]\n",
    "            nb_model = calculate_net_benefit(y_ext_binary, y_prob, dca_thresholds)\n",
    "            axes[1].plot(dca_thresholds, nb_model, \"-\", label=name, color=color, linewidth=2.5, alpha=0.9)\n",
    "        \n",
    "        axes[1].set_title(f\"Decision Curve: {class_label}\\n(External Validation Cohort)\", fontweight='bold')\n",
    "        axes[1].set_xlabel(\"Threshold Probability\", fontweight='bold')\n",
    "        axes[1].set_ylabel(\"Net Benefit\", fontweight='bold')\n",
    "        axes[1].legend(loc=\"upper right\")\n",
    "        axes[1].set_xlim([0, 0.8])\n",
    "        y_max = max(np.max(nb_all[(dca_thresholds < 0.8)]), 0.2) * 1.1 \n",
    "        axes[1].set_ylim([-0.05, y_max])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"External_Fig_{class_label.replace(' ', '_')}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(f\"External_Fig_{class_label.replace(' ', '_')}.pdf\", bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"å¤–éƒ¨éªŒè¯å›¾è¡¨ç»˜åˆ¶å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b4fc9b-0fd9-4821-b8ef-8fb17687778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 11. DCAå‡€è·ç›Šé¢ç§¯å›¾\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "COLORS = {'blue': '#6A76C4', 'red': '#CF5B89'} \n",
    "BOOTSTRAP_ROUNDS = 1000   \n",
    "SIG_THRESHOLD = 0.05      \n",
    "EXTERNAL_FILE_PATH = \"å¤–éƒ¨éªŒè¯é›†.xlsx\"\n",
    "CLASS_NAMES = {0: 'Low Trust', 1: 'Medium Trust', 2: 'High Trust'}\n",
    "\n",
    "# --- 1. ç¯å¢ƒå‡†å¤‡ ---\n",
    "print(f\"åˆå§‹åŒ–ç¯å¢ƒ (Bootstrap={BOOTSTRAP_ROUNDS}, Threshold={SIG_THRESHOLD})...\")\n",
    "target_index = 91\n",
    "\n",
    "if 'y_ext' in locals():\n",
    "    y_target_data = y_ext\n",
    "    print(\"   [Info] ä½¿ç”¨å†…å­˜ä¸­çš„ y_extã€‚\")\n",
    "else:\n",
    "    try:\n",
    "        if 'df_ext' not in locals():\n",
    "            df_ext = pd.read_excel(EXTERNAL_FILE_PATH, header=2)\n",
    "        raw_vals = df_ext.iloc[:, target_index].dropna().astype(float)\n",
    "        if 'bins' not in locals():\n",
    "            q1, q2 = np.percentile(raw_vals, [33.33, 66.67])\n",
    "            bins = [-np.inf, q1, q2, np.inf]\n",
    "        y_target_data = pd.cut(df_ext.iloc[:, target_index], bins=bins, labels=[0, 1, 2], include_lowest=True).astype(int)\n",
    "        print(\"   [Info] è‡ªåŠ¨åŠ è½½å¹¶é‡å»º y_ext æˆåŠŸã€‚\")\n",
    "    except:\n",
    "        print(\"   [Error] æ— æ³•åŠ è½½æ•°æ®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¼”ç¤ºã€‚\")\n",
    "        y_target_data = np.random.randint(0, 3, 100)\n",
    "\n",
    "y_ext_raw = np.array(y_target_data)\n",
    "\n",
    "# --- 2. æ ¸å¿ƒè®¡ç®—å‡½æ•° ---\n",
    "\n",
    "def calculate_net_benefit_curve(y_true, y_prob):\n",
    "    y_true = np.array(y_true); y_prob = np.array(y_prob)\n",
    "    thresholds = np.arange(0.01, 1.0, 0.01)\n",
    "    n = len(y_true)\n",
    "    nb_values = []\n",
    "    for thresh in thresholds:\n",
    "        tp = np.sum((y_prob >= thresh) & (y_true == 1))\n",
    "        fp = np.sum((y_prob >= thresh) & (y_true == 0))\n",
    "        weight = thresh / (1 - thresh)\n",
    "        nb = (tp / n) - (fp / n) * weight\n",
    "        nb_values.append(nb)\n",
    "    return np.array(nb_values)\n",
    "\n",
    "def calculate_areas(nb_values):\n",
    "    \"\"\"è®¡ç®—æ­£è´Ÿé¢ç§¯\"\"\"\n",
    "    pos_curve = np.maximum(nb_values, 0)\n",
    "    pos_area = np.trapz(pos_curve, dx=0.01)\n",
    "    neg_curve = np.minimum(nb_values, 0)\n",
    "    neg_area = abs(np.trapz(neg_curve, dx=0.01))\n",
    "    return pos_area, neg_area\n",
    "\n",
    "def calculate_treat_all_pos_area(y_true):\n",
    "    \"\"\"è®¡ç®—åŸºå‡†çº¿é¢ç§¯\"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    n = len(y_true)\n",
    "    prevalence = np.sum(y_true) / n\n",
    "    thresholds = np.arange(0.01, 1.0, 0.01)\n",
    "    nb_values = []\n",
    "    for thresh in thresholds:\n",
    "        weight = thresh / (1 - thresh)\n",
    "        nb = prevalence - (1 - prevalence) * weight\n",
    "        nb_values.append(nb)\n",
    "    pos_curve = np.maximum(np.array(nb_values), 0)\n",
    "    return np.trapz(pos_curve, dx=0.01)\n",
    "\n",
    "def calculate_pairwise_raw_p_values(model_data, y_true, n_boot=100):\n",
    "    \"\"\"è®¡ç®—åŸå§‹ P å€¼ (Bootstrap)\"\"\"\n",
    "    models = list(model_data.keys())\n",
    "    rng = np.random.default_rng(42)\n",
    "    n = len(y_true)\n",
    "    \n",
    "    obs_areas = {}\n",
    "    for m, p in model_data.items():\n",
    "        nb = calculate_net_benefit_curve(y_true, p)\n",
    "        pos, _ = calculate_areas(nb)\n",
    "        obs_areas[m] = pos\n",
    "        \n",
    "    pairs = list(combinations(models, 2))\n",
    "    obs_diffs = {pair: obs_areas[pair[0]] - obs_areas[pair[1]] for pair in pairs}\n",
    "    \n",
    "    boot_diffs = {pair: [] for pair in pairs}\n",
    "    for _ in range(n_boot):\n",
    "        indices = rng.choice(n, n, replace=True)\n",
    "        y_boot = y_true[indices]\n",
    "        for pair in pairs:\n",
    "            m1, m2 = pair\n",
    "            p1 = model_data[m1][indices]\n",
    "            p2 = model_data[m2][indices]\n",
    "            nb1 = calculate_net_benefit_curve(y_boot, p1)\n",
    "            nb2 = calculate_net_benefit_curve(y_boot, p2)\n",
    "            d1, _ = calculate_areas(nb1)\n",
    "            d2, _ = calculate_areas(nb2)\n",
    "            boot_diffs[pair].append(d1 - d2)\n",
    "            \n",
    "    raw_p_values = {}\n",
    "    for pair, diff_list in boot_diffs.items():\n",
    "        obs = obs_diffs[pair]\n",
    "        p = np.mean(np.abs(np.array(diff_list)) >= np.abs(obs))\n",
    "        if p == 0: p = 1 / (n_boot + 1)\n",
    "        raw_p_values[pair] = p\n",
    "    return raw_p_values\n",
    "\n",
    "def holm_bonferroni_correction(p_values_dict):\n",
    "    \"\"\"Holm-Bonferroni\"\"\"\n",
    "    if not p_values_dict: return {}\n",
    "    pairs = list(p_values_dict.keys())\n",
    "    raw_p = [p_values_dict[k] for k in pairs]\n",
    "    sorted_indices = np.argsort(raw_p)\n",
    "    m = len(raw_p)\n",
    "    adj_p = np.zeros(m)\n",
    "    current_max = 0\n",
    "    for i in range(m):\n",
    "        idx = sorted_indices[i]\n",
    "        p = raw_p[idx]\n",
    "        corrected = p * (m - i)\n",
    "        corrected = max(corrected, current_max)\n",
    "        current_max = corrected\n",
    "        adj_p[idx] = min(1.0, corrected)\n",
    "    result = {}\n",
    "    for i, pair in enumerate(pairs):\n",
    "        result[pair] = adj_p[i]\n",
    "    return result\n",
    "\n",
    "# --- 3. ç»˜å›¾æ‰§è¡Œ ---\n",
    "print(f\"å¯åŠ¨å…¨å¥—åˆ†æ (Alpha={SIG_THRESHOLD} | Correction=Holm | Boot={BOOTSTRAP_ROUNDS})...\")\n",
    "\n",
    "unique_classes = np.sort(np.unique(y_ext_raw))\n",
    "labels_map = CLASS_NAMES\n",
    "\n",
    "if 'best_models' not in locals():\n",
    "    print(\"é”™è¯¯: best_models æœªå®šä¹‰ã€‚\")\n",
    "else:\n",
    "    for target_class in unique_classes:\n",
    "        class_label = labels_map.get(target_class, f\"Class {target_class}\")\n",
    "        clean_name = class_label.replace(\" \", \"_\")\n",
    "        print(f\"\\nğŸ”µ [Processing] {class_label}\")\n",
    "        \n",
    "        y_binary = (y_ext_raw == target_class).astype(int)\n",
    "        baseline_pos_area = calculate_treat_all_pos_area(y_binary)\n",
    "        \n",
    "        current_models = {}    \n",
    "        plot_data = [] \n",
    "        \n",
    "        # --- A. å‡†å¤‡ç»˜å›¾æ•°æ® ---\n",
    "        for m_name, pipeline in best_models.items():\n",
    "            try:\n",
    "                if 'model_feature_config' in locals() and m_name in model_feature_config:\n",
    "                    feature_indices = model_feature_config[m_name]\n",
    "                    if hasattr(df_ext, 'iloc'):\n",
    "                         valid_indices = [i for i in feature_indices if i < df_ext.shape[1]]\n",
    "                         X_curr = df_ext.iloc[:, valid_indices]\n",
    "                    else:\n",
    "                         X_curr = np.zeros((len(y_binary), 1))\n",
    "\n",
    "                    if hasattr(pipeline, \"predict_proba\"):\n",
    "                        probs = pipeline.predict_proba(X_curr)\n",
    "                        p_target = probs[:, target_class]\n",
    "                        \n",
    "                        nb_curve = calculate_net_benefit_curve(y_binary, p_target)\n",
    "                        pos_area, neg_area = calculate_areas(nb_curve)\n",
    "                        \n",
    "                        height = pos_area\n",
    "                        delta = height - baseline_pos_area\n",
    "                        color = COLORS['blue'] if pos_area > neg_area else COLORS['red']\n",
    "                        \n",
    "                        plot_data.append({'name': m_name, 'height': height, 'color': color, 'delta': delta})\n",
    "                        current_models[m_name] = p_target\n",
    "            except: pass\n",
    "        \n",
    "        if not plot_data: continue\n",
    "\n",
    "        # --- B. è®¡ç®— P å€¼ (Holm-Bonferroni) ---\n",
    "        print(f\"   è¿è¡Œ {BOOTSTRAP_ROUNDS} æ¬¡æ¨¡æ‹Ÿ (æ ¡æ­£: Holm-Bonferroni)...\")\n",
    "        raw_p_dict = calculate_pairwise_raw_p_values(current_models, y_binary, n_boot=BOOTSTRAP_ROUNDS)\n",
    "        adj_p_dict = holm_bonferroni_correction(raw_p_dict)\n",
    "        \n",
    "        # --- C. ç»˜åˆ¶ DCA æŸ±çŠ¶å›¾ ---\n",
    "        plt.figure(figsize=(10, 7), dpi=300)\n",
    "        names = [d['name'] for d in plot_data]\n",
    "        heights = [d['height'] for d in plot_data]\n",
    "        colors = [d['color'] for d in plot_data]\n",
    "        deltas = [d['delta'] for d in plot_data]\n",
    "        x_pos = np.arange(len(names))\n",
    "        \n",
    "        bars = plt.bar(x_pos, heights, width=0.5, color=colors, edgecolor='black', alpha=0.9, zorder=3)\n",
    "        \n",
    "        # æ ‡æ³¨ Delta å€¼\n",
    "        for bar, d in zip(bars, deltas):\n",
    "            symbol = 'â†‘' if d > 0 else 'â†“'\n",
    "            text_str = f\"{symbol} {abs(d):.3f}\"\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, 0.005, text_str, \n",
    "                     ha='center', va='bottom', color='black', fontweight='bold', fontsize=10, zorder=5)\n",
    "\n",
    "        # åŠ¨æ€æ˜¾è‘—æ€§æ ‡æ³¨é€»è¾‘\n",
    "        sig_pairs = [(pair, p) for pair, p in adj_p_dict.items() if p < SIG_THRESHOLD]\n",
    "        \n",
    "        top_visual = max(heights) if heights else 0.1\n",
    "        final_top = top_visual * 1.3\n",
    "        \n",
    "        if sig_pairs:\n",
    "            sig_pairs.sort(key=lambda x: x[1]) \n",
    "            \n",
    "            line_start_y = top_visual + 0.02\n",
    "            step_y = 0.04  \n",
    "            \n",
    "            for i, ((m1, m2), p) in enumerate(sig_pairs):\n",
    "                idx1 = names.index(m1); idx2 = names.index(m2)\n",
    "                x1, x2 = min(idx1, idx2), max(idx1, idx2)\n",
    "                y_h = line_start_y + i * step_y\n",
    "                y_leg = 0.005\n",
    "                \n",
    "                plt.plot([x1, x1, x2, x2], [y_h - y_leg, y_h, y_h, y_h - y_leg], lw=1.2, c='black')\n",
    "                if p < 0.001: star = \"***\"\n",
    "                elif p < 0.01: star = \"**\"\n",
    "                else: star = \"*\"  \n",
    "                \n",
    "                plt.text((x1 + x2)/2, y_h, star, ha='center', va='bottom', color='black', fontsize=12, fontweight='bold')\n",
    "            \n",
    "            final_top = line_start_y + len(sig_pairs) * step_y + 0.05\n",
    "\n",
    "        plt.ylim(0, final_top)\n",
    "        plt.title(f\"Clinical Utility (Pos Area | Threshold < {SIG_THRESHOLD})\\nTarget: {class_label}\", fontsize=14, fontweight='bold', pad=15)\n",
    "        plt.xticks(x_pos, names, fontsize=11)\n",
    "        plt.ylabel(\"Area under net benefit curve\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"DCA_Bar_{clean_name}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(f\"   [å›¾è¡¨ 1] DCAæŸ±çŠ¶å›¾: DCA_Bar_{clean_name}.png\")\n",
    "\n",
    "        # --- D.Adj. P çƒ­åŠ›å›¾ ---\n",
    "        models_list = list(current_models.keys())\n",
    "        p_matrix = pd.DataFrame(np.nan, index=models_list, columns=models_list)\n",
    "        np.fill_diagonal(p_matrix.values, 1.0)\n",
    "        \n",
    "        for (m1, m2), p in adj_p_dict.items():\n",
    "            p_matrix.loc[m1, m2] = p\n",
    "            p_matrix.loc[m2, m1] = p\n",
    "            \n",
    "        plt.figure(figsize=(8, 6), dpi=300)\n",
    "        annot_labels = p_matrix.copy().astype(object)\n",
    "        \n",
    "        for i in range(len(models_list)):\n",
    "            for j in range(len(models_list)):\n",
    "                val = p_matrix.iloc[i, j]\n",
    "                if pd.isna(val): continue\n",
    "                if i == j: \n",
    "                    annot_labels.iloc[i, j] = \"\"\n",
    "                    continue\n",
    "                \n",
    "                # ğŸ¯ åŠ¨æ€æ–‡æœ¬é€»è¾‘ (æ ¸å¿ƒä¿®æ”¹)\n",
    "                if val < 0.001:\n",
    "                    txt = \"<.001\\n***\"\n",
    "                elif val < 0.01:\n",
    "                    txt = f\"{val:.3f}\\n**\"\n",
    "                elif val < 0.05:\n",
    "                    txt = f\"{val:.3f}\\n*\"\n",
    "                else:\n",
    "                    txt = f\"{val:.3f}\"\n",
    "                \n",
    "                annot_labels.iloc[i, j] = txt\n",
    "        \n",
    "        sns.heatmap(p_matrix, annot=annot_labels, fmt=\"\", \n",
    "                    cmap=\"Reds_r\", vmin=0, vmax=0.1, \n",
    "                    cbar_kws={'label': f'Adj. P-value (Holm)'},\n",
    "                    linewidths=1, linecolor='gray')\n",
    "        \n",
    "        plt.title(f\"Pairwise Comparison (Holm Adj. P)\\nTarget: {class_label}\", fontsize=14, fontweight='bold', pad=15)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"Heatmap_AdjP_{clean_name}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(f\"   [å›¾è¡¨ 2] çƒ­åŠ›å›¾: Heatmap_AdjP_{clean_name}.png\")\n",
    "\n",
    "        # --- E. å¯¼å‡º CSV ---\n",
    "        csv_data = []\n",
    "        for (m1, m2), ap in adj_p_dict.items():\n",
    "            rp = raw_p_dict.get((m1, m2), np.nan)\n",
    "            csv_data.append({\n",
    "                \"Category\": class_label,\n",
    "                \"Model A\": m1, \"Model B\": m2,\n",
    "                \"Raw P-value\": rp,\n",
    "                \"Adj. P-value\": ap,\n",
    "                \"Significant\": \"Yes\" if ap < SIG_THRESHOLD else \"No\"\n",
    "            })\n",
    "        pd.DataFrame(csv_data).to_csv(f\"Stats_Table_{clean_name}.csv\", index=False)\n",
    "        print(f\"   [è¡¨æ ¼ 3] ç»Ÿè®¡æ•°æ®è¡¨: Stats_Table_{clean_name}.csv\")\n",
    "\n",
    "print(\"\\n å…¨éƒ¨å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc14773-0d56-4747-949b-da0f8e6489b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 12.æ ¡å‡†æŒ‡æ ‡è¡¨æ ¼\n",
    "# ==========================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "\n",
    "# --- 1. å®šä¹‰è®¡ç®—å‡½æ•° ---\n",
    "def calculate_calibration_slope(y_true, y_prob):\n",
    "    eps = 1e-15\n",
    "    p = np.clip(np.asarray(y_prob), eps, 1 - eps)\n",
    "    x = np.log(p / (1 - p)).reshape(-1, 1)\n",
    "\n",
    "    lr = LogisticRegression(penalty=None, solver=\"lbfgs\", max_iter=2000)\n",
    "    lr.fit(x, np.asarray(y_true))\n",
    "    return float(lr.coef_[0][0])\n",
    "\n",
    "def get_class_proba(model, X, class_id):\n",
    "    classes = model.classes_\n",
    "    proba_col = int(np.where(classes == class_id)[0][0])\n",
    "    return model.predict_proba(X)[:, proba_col]\n",
    "\n",
    "def plot_academic_table(df_display, title, filename):\n",
    "    fig, ax = plt.subplots(figsize=(10, 3 + len(df_display)*0.3), dpi=300)\n",
    "    ax.axis('off')\n",
    "\n",
    "    the_table = ax.table(\n",
    "        cellText=df_display.values,\n",
    "        colLabels=df_display.columns,\n",
    "        loc='center',\n",
    "        cellLoc='center'\n",
    "    )\n",
    "\n",
    "    the_table.auto_set_font_size(False)\n",
    "    the_table.set_fontsize(11)\n",
    "    the_table.scale(1, 2.0)\n",
    "\n",
    "    for (row, col), cell in the_table.get_celld().items():\n",
    "        cell.set_text_props(fontfamily='sans-serif')\n",
    "        cell.set_facecolor('white')\n",
    "        cell.set_edgecolor('black')\n",
    "        cell.set_linewidth(1.0)\n",
    "\n",
    "        if row == 0:\n",
    "            cell.set_text_props(weight='bold', color='black')\n",
    "        else:\n",
    "            cell.set_text_props(weight='normal', color='black')\n",
    "\n",
    "    plt.title(title, fontsize=12, fontweight='bold', y=1.02, loc='center')\n",
    "\n",
    "    plt.savefig(f\"{filename}.png\", bbox_inches='tight', dpi=300)\n",
    "    plt.savefig(f\"{filename}.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"å›¾ç‰‡å·²ç”Ÿæˆ: {filename}.png\")\n",
    "\n",
    "\n",
    "# --- 2. ä¸»æ‰§è¡Œé€»è¾‘ ---\n",
    "if 'df_ext' in locals() and 'y_ext' in locals():\n",
    "    print(\"æ­£åœ¨ç”Ÿæˆæ ¡å‡†è¡¨æ ¼...\")\n",
    "\n",
    "    model_stats = {\n",
    "        name: {'Slope_Int': [], 'MSE_Int': [], 'Slope_Ext': [], 'MSE_Ext': []}\n",
    "        for name in best_models.keys()\n",
    "    }\n",
    "    results_list = []\n",
    "\n",
    "    # 1. éå†ç±»åˆ«\n",
    "    for class_id, class_label in CLASS_NAMES.items():\n",
    "        print(f\"   -> å¤„ç†ç±»åˆ«: {class_label}\")\n",
    "        y_int_bin = (y_test == class_id).astype(int)\n",
    "        y_ext_bin = (np.array(y_ext) == class_id).astype(int)\n",
    "\n",
    "        class_rows = []\n",
    "\n",
    "        for name, model in best_models.items():\n",
    "            # è·å–æ•°æ®\n",
    "            if 'model_feature_config' in globals():\n",
    "                f_idx = model_feature_config[name]\n",
    "                valid_idx = [i for i in f_idx if i < len(df.columns)]\n",
    "                cols = df.columns[valid_idx]\n",
    "                X_int = df_clean.loc[test_idx, cols]\n",
    "                X_ext = df_ext[cols]\n",
    "            else:\n",
    "                X_int = df_clean.loc[test_idx]\n",
    "                X_ext = df_ext\n",
    "\n",
    "            # æ¦‚ç‡åˆ—æŒ‰ model.classes_ å¯¹é½\n",
    "            p_int = get_class_proba(model, X_int, class_id)\n",
    "            p_ext = get_class_proba(model, X_ext, class_id)\n",
    "\n",
    "            # calibration slopeï¼ˆlogisticï¼‰\n",
    "            s_int = calculate_calibration_slope(y_int_bin, p_int)\n",
    "            m_int = mean_squared_error(y_int_bin, p_int)\n",
    "            s_ext = calculate_calibration_slope(y_ext_bin, p_ext)\n",
    "            m_ext = mean_squared_error(y_ext_bin, p_ext)\n",
    "\n",
    "            model_stats[name]['Slope_Int'].append(s_int)\n",
    "            model_stats[name]['MSE_Int'].append(m_int)\n",
    "            model_stats[name]['Slope_Ext'].append(s_ext)\n",
    "            model_stats[name]['MSE_Ext'].append(m_ext)\n",
    "\n",
    "            class_rows.append({\n",
    "                'Model': name,\n",
    "                'Slope (Int)': f\"{s_int:.3f}\",\n",
    "                'MSE (Int)': f\"{m_int:.3f}\",\n",
    "                'Slope (Ext)': f\"{s_ext:.3f}\",\n",
    "                'MSE (Ext)': f\"{m_ext:.3f}\"\n",
    "            })\n",
    "\n",
    "            results_list.append({\n",
    "                'Category': class_label, 'Model': name,\n",
    "                'Slope_Int': s_int, 'MSE_Int': m_int,\n",
    "                'Slope_Ext': s_ext, 'MSE_Ext': m_ext\n",
    "            })\n",
    "\n",
    "        plot_academic_table(\n",
    "            pd.DataFrame(class_rows),\n",
    "            title=f\"Table. Calibration Metrics - {class_label}\",\n",
    "            filename=f\"Table_Calibration_{class_label.replace(' ', '_')}\"\n",
    "        )\n",
    "\n",
    "    # 2. è®¡ç®— Macro-average\n",
    "    print(\"   -> è®¡ç®— Macro-average...\")\n",
    "    avg_rows = []\n",
    "    for name in best_models.keys():\n",
    "        avg_s_int = float(np.mean(model_stats[name]['Slope_Int']))\n",
    "        avg_m_int = float(np.mean(model_stats[name]['MSE_Int']))\n",
    "        avg_s_ext = float(np.mean(model_stats[name]['Slope_Ext']))\n",
    "        avg_m_ext = float(np.mean(model_stats[name]['MSE_Ext']))\n",
    "\n",
    "        avg_rows.append({\n",
    "            'Model': name,\n",
    "            'Slope (Int)': f\"{avg_s_int:.3f}\",\n",
    "            'MSE (Int)': f\"{avg_m_int:.3f}\",\n",
    "            'Slope (Ext)': f\"{avg_s_ext:.3f}\",\n",
    "            'MSE (Ext)': f\"{avg_m_ext:.3f}\"\n",
    "        })\n",
    "\n",
    "        results_list.append({\n",
    "            'Category': 'Total Average', 'Model': name,\n",
    "            'Slope_Int': avg_s_int, 'MSE_Int': avg_m_int,\n",
    "            'Slope_Ext': avg_s_ext, 'MSE_Ext': avg_m_ext\n",
    "        })\n",
    "\n",
    "    plot_academic_table(\n",
    "        pd.DataFrame(avg_rows),\n",
    "        title=\"Table. Calibration Metrics - Total Average (Macro)\",\n",
    "        filename=\"Table_Calibration_Total_Average\"\n",
    "    )\n",
    "\n",
    "    # å¯¼å‡º CSV\n",
    "    pd.DataFrame(results_list).to_csv(\"Calibration_Metrics_Academic.csv\", index=False)\n",
    "    print(\"\\nğŸ“‹ åŸå§‹æ•°æ®å·²ä¿å­˜ä¸º CSV\")\n",
    "else:\n",
    "    print(\"æœªæ£€æµ‹åˆ°å¤–éƒ¨éªŒè¯æ•°æ®ã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade2bc9-11db-40f4-9d32-5d7326725cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
